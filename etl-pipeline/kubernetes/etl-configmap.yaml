apiVersion: v1
kind: ConfigMap
metadata:
  name: etl-job-templates
  namespace: di-kubernets-staging
data:
  extraction-job.yaml: |
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: extract-${TABLE_NAME}-${PARTITION_ID}
      namespace: di-kubernets-staging
      labels:
        app: etl-extractor
        table: ${TABLE_NAME}
        partition: ${PARTITION_ID}
        primary-key-val: ${PRIMARY_KEY_VAL}  # Add primary key value as metadata
    spec:
      parallelism: 1
      completions: 1
      backoffLimit: 3
      template:
        spec:
          containers:
          - name: extractor
            image: docker-registry.cfdata.org/u/santhoshi/pg_stripe/58/etl-extractor:latest@sha256:c89f755e3c6f159388777a01f1a6cae47207984c9af04d2057cc597f9bd98d4d
            resources:
              requests:
                memory: "2Gi"
                cpu: "500m"
              limits:
                memory: "2Gi"
                cpu: "500m"
            env:
            - name: POSTGRES_CONNECTION
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: connection-string
            - name: GCP_CREDENTIALS_BASE64
              valueFrom:
                secretKeyRef:
                  name: gcp-credentials-base64
                  key: credentials      
            - name: TABLE_NAME
              value: "${TABLE_NAME}"
            - name: PRIMARY_KEY
              value: "${PRIMARY_KEY}"
            - name: PRIMARY_KEY_VAL
              value: "${PRIMARY_KEY_VAL}"  # Pass primary key value as environment variable
            - name: PARTITION_ID
              value: "${PARTITION_ID}"
            - name: TOTAL_PARTITIONS
              value: "${TOTAL_PARTITIONS}"
            - name: CHUNK_SIZE
              value: "250000"
            - name: COMPLEX_CHUNK_SIZE
              value: "10000"
            - name: OUTPUT_DIR
              value: "${TABLE_NAME}/${PARTITION_ID}"
            - name: COMPRESSION_LEVEL
              value: "9"
          restartPolicy: OnFailure

  loading-job.yaml: |
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: load-${TABLE_NAME}
      namespace: di-kubernets-staging
    spec:
      parallelism: 1
      completions: 1
      backoffLimit: 3
      template:
        spec:
          containers:
          - name: loader
            image: docker-registry.cfdata.org/u/santhoshi/pg_stripe/58/etl-loader:latest@sha256:b55674392df01bf4885694c806a8e7100c15bce04a886cda0b1b85b07e3a7dd9
            resources:
              requests:
                memory: "4Gi"
                cpu: "2"
              limits:
                memory: "8Gi"
                cpu: "4"
            env:
            - name: GCP_CREDENTIALS_BASE64
              valueFrom:
                secretKeyRef:
                  name: gcp-credentials-base64
                  key: credentials
            - name: SOURCE_TABLE
              value: "${TABLE_NAME}"
            - name: DESTINATION_TABLE
              value: "${DESTINATION_TABLE}"
            - name: DATA_DIR
              value: "${TABLE_NAME}"
            - name: BATCH_SIZE
              value: "5000"
            - name: BIGQUERY_PROJECT
              value: "${BIGQUERY_PROJECT}"
            - name: BIGQUERY_DATASET
              value: "${BIGQUERY_DATASET}"
          restartPolicy: OnFailure
